{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers==4.28.1","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:23.171803Z","iopub.execute_input":"2023-05-22T22:00:23.174298Z","iopub.status.idle":"2023-05-22T22:00:23.179764Z","shell.execute_reply.started":"2023-05-22T22:00:23.174256Z","shell.execute_reply":"2023-05-22T22:00:23.178940Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:23.205352Z","iopub.execute_input":"2023-05-22T22:00:23.207117Z","iopub.status.idle":"2023-05-22T22:00:23.210976Z","shell.execute_reply.started":"2023-05-22T22:00:23.207080Z","shell.execute_reply":"2023-05-22T22:00:23.209925Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, TextDataset, DataCollatorForLanguageModeling\nfrom transformers import Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, TextDataset, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:23.234559Z","iopub.execute_input":"2023-05-22T22:00:23.235141Z","iopub.status.idle":"2023-05-22T22:00:29.099646Z","shell.execute_reply.started":"2023-05-22T22:00:23.235108Z","shell.execute_reply":"2023-05-22T22:00:29.098695Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/scrapped-lyricsfinallcsv/Scrapped_lyricsfinall.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.101726Z","iopub.execute_input":"2023-05-22T22:00:29.102519Z","iopub.status.idle":"2023-05-22T22:00:29.195547Z","shell.execute_reply.started":"2023-05-22T22:00:29.102479Z","shell.execute_reply":"2023-05-22T22:00:29.194656Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data[\"Lyrics\"]=data[\"Lyrics\"].str.replace('\\n',' ')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.197182Z","iopub.execute_input":"2023-05-22T22:00:29.197537Z","iopub.status.idle":"2023-05-22T22:00:29.205950Z","shell.execute_reply.started":"2023-05-22T22:00:29.197504Z","shell.execute_reply":"2023-05-22T22:00:29.205061Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data[\"Lyrics\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.208492Z","iopub.execute_input":"2023-05-22T22:00:29.209463Z","iopub.status.idle":"2023-05-22T22:00:29.223245Z","shell.execute_reply.started":"2023-05-22T22:00:29.209427Z","shell.execute_reply":"2023-05-22T22:00:29.222357Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0       انا ادري مين انا يا حبيبي مءمن ان السعي غير مص...\n1       ايه يا اميره عن يدي بعيده عايشه عيشه غير العيش...\n2       والموج عالي بس سباح وهعومواللي يعيش بقي يا ما ...\n3       اللازمه ويجزدايره ع المصلحهكلها دايره ع المصلح...\n4       عيني منها بشكل جدي وتقيله مش تقلانه اتبخر سحري...\n                              ...                        \n1023    اوپا اوپا اوپا اوپا ها ماشي ها ماشي اوپا اوپا ...\n1024    تجيلي الصبح قبل الشغل رايق زي  بعد الضهر برفع ...\n1025    منمتش من امبارح عشان شاحب قفلت التكييف قامت سا...\n1026    قابلتها مره بقت my bae بتشدني جامد اكني Lion k...\n1027    انا بكلم واحده تانيه وبقولك عشان اريح عشان مبق...\nName: Lyrics, Length: 1028, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"data[\"input_text\"] = \"artist: \" + data[\"Artist\"] + \" genre: \" + data[\"Genre\"].astype(str) \n\n# data[\"input_text\"] = \"artist: \" + data[\"Artist\"] + \" genre: \" + data[\"Genre\"].astype(str) + \" lyrics: \" + data['Lyrics'].str.split('\\n').str[:4].str.join('\\n')\ndata[\"target_text\"] = data[\"Lyrics\"]\ndata = data[[\"input_text\", \"target_text\"]]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.224409Z","iopub.execute_input":"2023-05-22T22:00:29.225021Z","iopub.status.idle":"2023-05-22T22:00:29.236966Z","shell.execute_reply.started":"2023-05-22T22:00:29.224987Z","shell.execute_reply":"2023-05-22T22:00:29.235831Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# dataset = Dataset.from_pandas(data)\n# train_dataset, test_dataset = dataset.train_test_split(test_size=0.1)\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.238425Z","iopub.execute_input":"2023-05-22T22:00:29.239062Z","iopub.status.idle":"2023-05-22T22:00:29.251544Z","shell.execute_reply.started":"2023-05-22T22:00:29.239027Z","shell.execute_reply":"2023-05-22T22:00:29.250714Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.252964Z","iopub.execute_input":"2023-05-22T22:00:29.253292Z","iopub.status.idle":"2023-05-22T22:00:29.267284Z","shell.execute_reply.started":"2023-05-22T22:00:29.253261Z","shell.execute_reply":"2023-05-22T22:00:29.266268Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                       input_text  \\\n898  artist: ايهاب توفيق genre: 1   \n66    artist: مروان موسي genre: 0   \n717      artist: العسيلي genre: 1   \n67    artist: مروان موسي genre: 0   \n260    artist: تامر حسني genre: 1   \n..                            ...   \n458    artist: محمد منير genre: 0   \n330    artist: رامي صبري genre: 0   \n466    artist: محمد منير genre: 2   \n121  artist: ابو الانوار genre: 0   \n860        artist: اصالة genre: 2   \n\n                                           target_text  \n898  مشاعري معاك حبيبي بايه تفسرها لاول مره حاجه في...  \n66   عصام كن انت البطل كن الكينج بضربه واحده تحدي ا...  \n717  خاينه نسيتي اللي قلنا انا وانتي عليهقلنا هنبعد...  \n67   اه يا حبيبتي كان نفسي تكوني موجوده معانا  نزل ...  \n260  انا مقدرش ابعد ثانيهانا بعدك مليش في الدنيايا ...  \n..                                                 ...  \n458  جي من بلاد البعيده لا زاد ولا ميه وغريتي صحبتي...  \n330  غمضت عيني وقولت نفسي اشوفها ثانيوالمس ايديها و...  \n466  يا عزيز عيني وانا بدي اروح بلدي ليله نمت فيها ...  \n121  كلمات اغنيه تلاته زيها ابيوسف و ابو الانوار مش...  \n860  يا قلبي شو بدك منو بعدك عم تسال عنوشكلك عم تنس...  \n\n[925 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>target_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>898</th>\n      <td>artist: ايهاب توفيق genre: 1</td>\n      <td>مشاعري معاك حبيبي بايه تفسرها لاول مره حاجه في...</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>artist: مروان موسي genre: 0</td>\n      <td>عصام كن انت البطل كن الكينج بضربه واحده تحدي ا...</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>artist: العسيلي genre: 1</td>\n      <td>خاينه نسيتي اللي قلنا انا وانتي عليهقلنا هنبعد...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>artist: مروان موسي genre: 0</td>\n      <td>اه يا حبيبتي كان نفسي تكوني موجوده معانا  نزل ...</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>artist: تامر حسني genre: 1</td>\n      <td>انا مقدرش ابعد ثانيهانا بعدك مليش في الدنيايا ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>artist: محمد منير genre: 0</td>\n      <td>جي من بلاد البعيده لا زاد ولا ميه وغريتي صحبتي...</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>artist: رامي صبري genre: 0</td>\n      <td>غمضت عيني وقولت نفسي اشوفها ثانيوالمس ايديها و...</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>artist: محمد منير genre: 2</td>\n      <td>يا عزيز عيني وانا بدي اروح بلدي ليله نمت فيها ...</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>artist: ابو الانوار genre: 0</td>\n      <td>كلمات اغنيه تلاته زيها ابيوسف و ابو الانوار مش...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>artist: اصالة genre: 2</td>\n      <td>يا قلبي شو بدك منو بعدك عم تسال عنوشكلك عم تنس...</td>\n    </tr>\n  </tbody>\n</table>\n<p>925 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data['input_text'][0]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.268747Z","iopub.execute_input":"2023-05-22T22:00:29.269197Z","iopub.status.idle":"2023-05-22T22:00:29.275866Z","shell.execute_reply.started":"2023-05-22T22:00:29.269162Z","shell.execute_reply":"2023-05-22T22:00:29.274751Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'artist: ويجز genre: 4'"},"metadata":{}}]},{"cell_type":"code","source":"train_data['target_text'][0]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.277532Z","iopub.execute_input":"2023-05-22T22:00:29.278326Z","iopub.status.idle":"2023-05-22T22:00:29.284829Z","shell.execute_reply.started":"2023-05-22T22:00:29.278292Z","shell.execute_reply":"2023-05-22T22:00:29.283925Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'انا ادري مين انا يا حبيبي مءمن ان السعي غير مصيري رميت والبحر يشهد بتعوزني تلاقيني بطل وقت مواجهه وشعبي مستنيني زي ما يكون بحلم تعالي شوف الشغل في السما بلمع ومش مستني الشكر وبالظبط دي كوره عشان كده بغني بقول ومن قلبي الكوره تسمعني حيوا اللي يجمعنا وما عاش اللي يفرقنا غنيها وسمعنا حيوا كل عباد الله حيوا اللي يجمعنا وما عاش اللي يفرقنا غنيها وسمعنا حيوا كل عباد الله عز العرب تعالي شوف الكرم عندي كوره وهدف عندي كوره وطرب عز العرب تعالي شوف الكرم عندي كوره وهدف عندي كوره وطرب حيوا مرحب و الشباك طارحه العرب ترعاكي يا فرحه سدد وانا اشوف اقول ما شاء الله من قطر لكل عباد الله ميجيبهاش غير ابطالها وبروس مرفوعه بحضرها كل البشر هتشرفنا كل العالم هنعرفها لا اسال شكلك ولا عنوانك مرحب بيك ناسك ومكانك الكوره لغه كل العالم ورينا كل اللي في امكانك وفيت قد ما وعدت حققت قد ما حلمت كلام كتير معمليش سقف بعد غيمه ضحكتلي الشمس ورفرف يا علمي اعلي وجدد املي انا طموح وسريع وعنيد كاس العالم عندي والرب واحد بالحب واحد ده انا وانت انسان بنسي وبسامح قالوا اختلفنا وانا قلت جايز بس فيكوا منا ولسه حبايب حيوا اللي يجمعنا وما عاش اللي يفرقنا غنيها وسمعنا حيوا كل عباد الله حيوا اللي يجمعنا وما عاش اللي يفرقنا غنيها وسمعنا حيوا كل عباد الله حيوا مرحب و الشباك طارحه العرب ترعاكي يا فرحه سدد وانا اشوف اقول ما شاء الله من قطر لكل عباد الله حيوا مرحب و الشباك طارحه العرب ترعاكي يا فرحه سدد وانا اشوف اقول ما شاء الله من قطر لكل عباد الله عز العرب تعالي شوف الكرم عندي كوره وهدف عندي كوره وطرب عز العرب تعالي شوف الكرم عندي كوره وهدف عندي كوره وطرب'"},"metadata":{}}]},{"cell_type":"code","source":"# !pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.289769Z","iopub.execute_input":"2023-05-22T22:00:29.290673Z","iopub.status.idle":"2023-05-22T22:00:29.294197Z","shell.execute_reply.started":"2023-05-22T22:00:29.290640Z","shell.execute_reply":"2023-05-22T22:00:29.293271Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(\"aubmindlab/aragpt2-base\")\nmodel = GPT2LMHeadModel.from_pretrained(\"aubmindlab/aragpt2-base\")\n# tokenizer = T5Tokenizer.from_pretrained(\"UBC-NLP/AraT5-base\")\n# model = T5ForConditionalGeneration.from_pretrained(\"UBC-NLP/AraT5-base\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:29.295592Z","iopub.execute_input":"2023-05-22T22:00:29.296236Z","iopub.status.idle":"2023-05-22T22:00:37.653167Z","shell.execute_reply.started":"2023-05-22T22:00:29.296203Z","shell.execute_reply":"2023-05-22T22:00:37.651919Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ntrain_dataset = Dataset.from_dict(train_data)\ntest_dataset = Dataset.from_dict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:37.654899Z","iopub.execute_input":"2023-05-22T22:00:37.655502Z","iopub.status.idle":"2023-05-22T22:00:37.675646Z","shell.execute_reply.started":"2023-05-22T22:00:37.655461Z","shell.execute_reply":"2023-05-22T22:00:37.674782Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:37.677087Z","iopub.execute_input":"2023-05-22T22:00:37.677417Z","iopub.status.idle":"2023-05-22T22:00:37.684154Z","shell.execute_reply.started":"2023-05-22T22:00:37.677377Z","shell.execute_reply":"2023-05-22T22:00:37.683021Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 925\n})"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:37.685761Z","iopub.execute_input":"2023-05-22T22:00:37.686508Z","iopub.status.idle":"2023-05-22T22:00:37.694050Z","shell.execute_reply.started":"2023-05-22T22:00:37.686475Z","shell.execute_reply":"2023-05-22T22:00:37.693023Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 103\n})"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef tokenize(example):\n    input_text = example[\"input_text\"]\n    target_text = example[\"target_text\"]\n\n    input_tokens = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=128)\n    target_tokens = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=128)\n\n    return {\n        \"input_ids\": np.array(input_tokens[\"input_ids\"]),\n        \"attention_mask\": np.array(input_tokens[\"attention_mask\"]),\n        \"labels\": np.array(target_tokens[\"input_ids\"]),\n    }\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:37.695393Z","iopub.execute_input":"2023-05-22T22:00:37.695913Z","iopub.status.idle":"2023-05-22T22:00:37.703921Z","shell.execute_reply.started":"2023-05-22T22:00:37.695861Z","shell.execute_reply":"2023-05-22T22:00:37.703039Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# train_dataset = train_dataset.map(tokenize, batched=True,remove_columns=[\"input_text\",\"target_text\"])\n# test_dataset = test_dataset.map(tokenize, batched=True,remove_columns=[\"input_text\",\"target_text\"])\ntrain_dataset = train_dataset.map(tokenize, batched=True, remove_columns=[\"input_text\", \"target_text\"])\ntest_dataset = test_dataset.map(tokenize, batched=True, remove_columns=[\"input_text\", \"target_text\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:37.705237Z","iopub.execute_input":"2023-05-22T22:00:37.705610Z","iopub.status.idle":"2023-05-22T22:00:45.007300Z","shell.execute_reply.started":"2023-05-22T22:00:37.705577Z","shell.execute_reply":"2023-05-22T22:00:45.006372Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73a33fa1f79474cb501fc3853db0ae3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb02977442fd4dac8a2a0f0b3946c6b1"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:45.008569Z","iopub.execute_input":"2023-05-22T22:00:45.009573Z","iopub.status.idle":"2023-05-22T22:00:45.016137Z","shell.execute_reply.started":"2023-05-22T22:00:45.009537Z","shell.execute_reply":"2023-05-22T22:00:45.015267Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 925\n})"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:45.017284Z","iopub.execute_input":"2023-05-22T22:00:45.018392Z","iopub.status.idle":"2023-05-22T22:00:45.028868Z","shell.execute_reply.started":"2023-05-22T22:00:45.018358Z","shell.execute_reply":"2023-05-22T22:00:45.027851Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 103\n})"},"metadata":{}}]},{"cell_type":"code","source":"# training_args = Seq2SeqTrainingArguments(\n#     output_dir=\"output\",\n#     num_train_epochs=3,\n#     per_device_train_batch_size=4,\n#     per_device_eval_batch_size=4,\n#     evaluation_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     learning_rate=3e-5,\n#     task = \"title_generation\" --text_column \"document\" --summary_column \"title\"\n# )\n\n# trainer = Seq2SeqTrainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     eval_dataset=test_dataset,\n#     tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:00:45.030345Z","iopub.execute_input":"2023-05-22T22:00:45.030875Z","iopub.status.idle":"2023-05-22T22:00:45.039019Z","shell.execute_reply.started":"2023-05-22T22:00:45.030842Z","shell.execute_reply":"2023-05-22T22:00:45.038138Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\nfrom sklearn.metrics import accuracy_score\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred.predictions, eval_pred.label_ids\n    predictions = logits.argmax(axis=-1)\n    acc = accuracy_score(labels, predictions)\n    return {\n        'accuracy': acc,\n    }\n\ntraining_args = TrainingArguments(\n    output_dir=\"./output\",\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    save_steps=10_000,\n    save_total_limit=2,\n    evaluation_strategy=\"epoch\",\n    save_strategy='epoch'\n)\n\nfrom transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_metrics\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:03:51.378452Z","iopub.execute_input":"2023-05-22T22:03:51.378808Z","iopub.status.idle":"2023-05-22T22:03:51.399745Z","shell.execute_reply.started":"2023-05-22T22:03:51.378779Z","shell.execute_reply":"2023-05-22T22:03:51.397373Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:03:55.293265Z","iopub.execute_input":"2023-05-22T22:03:55.293629Z","iopub.status.idle":"2023-05-22T22:04:16.894998Z","shell.execute_reply.started":"2023-05-22T22:03:55.293602Z","shell.execute_reply":"2023-05-22T22:04:16.889818Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='117' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [116/116 00:20, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='9' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 9/13 00:00 < 00:00, 16.59 it/s]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2021\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2021\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   2025\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2287\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2285\u001b[0m             metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2287\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2993\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2990\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2992\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2993\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3003\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3201\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3200\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[0;32m-> 3201\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_prediction_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   3204\u001b[0m \u001b[38;5;66;03m# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:116\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    119\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    120\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:75\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     72\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     78\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.69 GiB (GPU 0; 15.90 GiB total capacity; 9.41 GiB already allocated; 2.20 GiB free; 12.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 2.69 GiB (GPU 0; 15.90 GiB total capacity; 9.41 GiB already allocated; 2.20 GiB free; 12.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"# model.save_pretrained(\"fine_tuned_t5\")\n# tokenizer.save_pretrained(\"fine_tuned_t5\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:50.363775Z","iopub.status.idle":"2023-05-22T22:01:50.366842Z","shell.execute_reply.started":"2023-05-22T22:01:50.366582Z","shell.execute_reply":"2023-05-22T22:01:50.366608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # model = T5ForConditionalGeneration.from_pretrained(\"fine_tuned_t5\")\n# # tokenizer = T5Tokenizer.from_pretrained(\"fine_tuned_t5\")\n\n# def generate_lyrics(artist, genre):\n#     input_text = f\"artist: {artist} genre: {genre} lyrics:\"\n# # input_text = f\"'artist: ويجز genre: 4\"\n# input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to('cuda')\n# output_ids = model.generate(input_ids, max_length=128)\n# print(tokenizer.decode(output_ids[0]))\n\n# generated_lyrics = generate_lyrics(\"ويجز\", \"1\")\n# print(generated_lyrics)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:50.370773Z","iopub.status.idle":"2023-05-22T22:01:50.373177Z","shell.execute_reply.started":"2023-05-22T22:01:50.372882Z","shell.execute_reply":"2023-05-22T22:01:50.372927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_text = \"انا ادري مين انا يا حبيبي\"\ninput_text=\"artist: ويجز genre: 4\"\ninput_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\noutput = model.generate(input_ids, max_length=128)\n# print(tokenizer.batch_decode(output[0]))\nfor i, generated_text in enumerate(tokenizer.batch_decode(output)):\n    print(f\"Generated text {i + 1}:\")\n    print(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:50.376215Z","iopub.status.idle":"2023-05-22T22:01:50.376993Z","shell.execute_reply.started":"2023-05-22T22:01:50.376727Z","shell.execute_reply":"2023-05-22T22:01:50.376751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}